#!/usr/bin/env python3
"""
ReID ç‰¹å¾æå–å™¨å°è£…
æ”¯æŒ FastReID å’Œ OSNet ç­‰è½»é‡çº§æ¨¡å‹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import numpy as np
import cv2
from pathlib import Path
from typing import List, Tuple, Union, Optional


class FastReIDExtractor:
    """
    FastReID ç‰¹å¾æå–å™¨
    é’ˆå¯¹ MOT20 åœºæ™¯ä¼˜åŒ–çš„è¡Œäººå¤–è§‚ç‰¹å¾æå–
    """
    
    # æ ‡å‡†è¡Œäººå›¾åƒå°ºå¯¸
    INPUT_SIZE = (128, 384)  # (å®½, é«˜)
    
    # å½’ä¸€åŒ–å‚æ•° (ImageNet)
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]
    
    def __init__(
        self,
        model_path: str,
        device: str = "cuda:0",
        feature_dim: int = 128,
        batch_size: int = 32,
        half_precision: bool = True,
    ):
        """
        åˆå§‹åŒ–ç‰¹å¾æå–å™¨
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
            feature_dim: ç‰¹å¾ç»´åº¦
            batch_size: æ‰¹å¤„ç†å¤§å°
            half_precision: æ˜¯å¦ä½¿ç”¨FP16
        """
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.feature_dim = feature_dim
        self.batch_size = batch_size
        self.half_precision = half_precision and self.device.type == "cuda"
        
        # åŠ è½½æ¨¡å‹
        self._load_model(model_path)
        
        # é¢„çƒ­
        self._warmup()
    
    def _load_model(self, model_path: str):
        """åŠ è½½æ¨¡å‹"""
        model_path = Path(model_path)
        
        if not model_path.exists():
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°ReIDæ¨¡å‹ {model_path}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
            self.model = self._build_dummy_model()
        else:
            try:
                # å°è¯•åŠ è½½FastReIDæ¨¡å‹
                checkpoint = torch.load(model_path, map_location="cpu")
                
                if "model" in checkpoint:
                    state_dict = checkpoint["model"]
                elif "state_dict" in checkpoint:
                    state_dict = checkpoint["state_dict"]
                else:
                    state_dict = checkpoint
                
                self.model = self._build_model()
                self.model.load_state_dict(state_dict, strict=False)
                print(f"åŠ è½½FastReIDæ¨¡å‹: {model_path}")
                
            except Exception as e:
                print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
                self.model = self._build_dummy_model()
        
        self.model = self.model.to(self.device).eval()
        
        if self.half_precision:
            self.model = self.model.half()
            print("ReIDå¯ç”¨ FP16 åŠç²¾åº¦æ¨ç†")
    
    def _build_model(self) -> nn.Module:
        """æ„å»ºFastReIDæ¨¡å‹ (ResNet50éª¨å¹²)"""
        try:
            from torchvision.models import resnet50, ResNet50_Weights
            
            class FastReIDModel(nn.Module):
                def __init__(self, feature_dim=128):
                    super().__init__()
                    # ä½¿ç”¨ResNet50ä½œä¸ºéª¨å¹²
                    backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)
                    self.backbone = nn.Sequential(*list(backbone.children())[:-2])
                    
                    # å…¨å±€å¹³å‡æ± åŒ–
                    self.gap = nn.AdaptiveAvgPool2d(1)
                    
                    # BNNeck
                    self.bnneck = nn.BatchNorm1d(2048)
                    self.bnneck.bias.requires_grad_(False)
                    
                    # é™ç»´åˆ°ç›®æ ‡ç»´åº¦
                    self.fc = nn.Linear(2048, feature_dim)
                    self.bn_final = nn.BatchNorm1d(feature_dim)
                
                def forward(self, x):
                    x = self.backbone(x)
                    x = self.gap(x)
                    x = x.view(x.size(0), -1)
                    x = self.bnneck(x)
                    x = self.fc(x)
                    x = self.bn_final(x)
                    # L2å½’ä¸€åŒ–
                    x = F.normalize(x, p=2, dim=1)
                    return x
            
            return FastReIDModel(self.feature_dim)
            
        except ImportError:
            return self._build_dummy_model()
    
    def _build_dummy_model(self) -> nn.Module:
        """æ„å»ºå ä½æ¨¡å‹"""
        class DummyReIDModel(nn.Module):
            def __init__(self, feature_dim=128):
                super().__init__()
                self.feature_dim = feature_dim
                self.conv = nn.Sequential(
                    nn.Conv2d(3, 64, 7, stride=2, padding=3),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(3, stride=2, padding=1),
                    nn.AdaptiveAvgPool2d(1),
                )
                self.fc = nn.Linear(64, feature_dim)
            
            def forward(self, x):
                x = self.conv(x)
                x = x.view(x.size(0), -1)
                x = self.fc(x)
                return F.normalize(x, p=2, dim=1)
        
        return DummyReIDModel(self.feature_dim)
    
    def _warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        dummy_input = torch.zeros(
            1, 3, self.INPUT_SIZE[1], self.INPUT_SIZE[0],
            device=self.device
        )
        if self.half_precision:
            dummy_input = dummy_input.half()
        
        with torch.no_grad():
            for _ in range(3):
                _ = self.model(dummy_input)
        
        print("ReIDæ¨¡å‹é¢„çƒ­å®Œæˆ")
    
    def preprocess(self, image: np.ndarray) -> torch.Tensor:
        """
        é¢„å¤„ç†å•å¼ å›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C) BGRæ ¼å¼
            
        Returns:
            é¢„å¤„ç†åçš„å¼ é‡
        """
        # è°ƒæ•´å°ºå¯¸
        img = cv2.resize(image, self.INPUT_SIZE)
        
        # BGR -> RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # å½’ä¸€åŒ–
        img = img.astype(np.float32) / 255.0
        
        # æ ‡å‡†åŒ–
        mean = np.array(self.MEAN).reshape(1, 1, 3)
        std = np.array(self.STD).reshape(1, 1, 3)
        img = (img - mean) / std
        
        # HWC -> CHW
        img = np.transpose(img, (2, 0, 1))
        
        # è½¬æ¢ä¸ºå¼ é‡
        tensor = torch.from_numpy(img).unsqueeze(0).to(self.device)
        
        if self.half_precision:
            tensor = tensor.half()
        
        return tensor
    
    @torch.no_grad()
    def extract(self, image: np.ndarray) -> np.ndarray:
        """
        æå–å•å¼ å›¾åƒç‰¹å¾
        
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C) BGRæ ¼å¼
            
        Returns:
            ç‰¹å¾å‘é‡ (feature_dim,)
        """
        tensor = self.preprocess(image)
        feature = self.model(tensor)
        return feature.cpu().numpy().squeeze()
    
    @torch.no_grad()
    def extract_batch(
        self,
        images: List[np.ndarray]
    ) -> np.ndarray:
        """
        æ‰¹é‡æå–ç‰¹å¾
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            
        Returns:
            ç‰¹å¾çŸ©é˜µ (N, feature_dim)
        """
        if not images:
            return np.zeros((0, self.feature_dim), dtype=np.float32)
        
        features = []
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(images), self.batch_size):
            batch_images = images[i:i + self.batch_size]
            
            # é¢„å¤„ç†æ‰¹æ¬¡
            batch_tensors = []
            for img in batch_images:
                tensor = self.preprocess(img)
                batch_tensors.append(tensor)
            
            batch_input = torch.cat(batch_tensors, dim=0)
            
            # æ¨ç†
            batch_features = self.model(batch_input)
            features.append(batch_features.cpu().numpy())
        
        return np.concatenate(features, axis=0)
    
    def extract_from_detections(
        self,
        frame: np.ndarray,
        detections: np.ndarray,
        expand_ratio: float = 0.1
    ) -> np.ndarray:
        """
        ä»æ£€æµ‹æ¡†ä¸­æå–ç‰¹å¾
        
        Args:
            frame: åŸå§‹å¸§
            detections: æ£€æµ‹æ¡† (N, 4+) [x1, y1, x2, y2, ...]
            expand_ratio: è¾¹ç•Œæ¡†æ‰©å±•æ¯”ä¾‹
            
        Returns:
            ç‰¹å¾çŸ©é˜µ (N, feature_dim)
        """
        # å¤„ç†ç©ºæ£€æµ‹æˆ–æ— æ•ˆè¾“å…¥
        if detections is None or len(detections) == 0:
            return np.zeros((0, self.feature_dim), dtype=np.float32)
        
        # ç¡®ä¿æ˜¯äºŒç»´æ•°ç»„
        if detections.ndim == 1:
            detections = detections.reshape(1, -1)
        
        crops = []
        h, w = frame.shape[:2]
        
        for det in detections:
            # ç¡®ä¿ det è‡³å°‘æœ‰4ä¸ªå…ƒç´ 
            if len(det) < 4:
                continue
            x1, y1, x2, y2 = map(int, det[:4])
            
            # æ‰©å±•è¾¹ç•Œæ¡†
            bw, bh = x2 - x1, y2 - y1
            cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
            
            new_w = bw * (1 + expand_ratio)
            new_h = bh * (1 + expand_ratio)
            
            x1 = max(0, int(cx - new_w / 2))
            y1 = max(0, int(cy - new_h / 2))
            x2 = min(w, int(cx + new_w / 2))
            y2 = min(h, int(cy + new_h / 2))
            
            crop = frame[y1:y2, x1:x2]
            
            # å¤„ç†æ— æ•ˆè£å‰ª
            if crop.size == 0:
                crop = np.zeros((64, 32, 3), dtype=np.uint8)
            
            crops.append(crop)
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆè£å‰ªï¼Œè¿”å›ç©ºç‰¹å¾
        if not crops:
            return np.zeros((0, self.feature_dim), dtype=np.float32)
        
        return self.extract_batch(crops)


class OSNetExtractor(FastReIDExtractor):
    """
    OSNet è½»é‡çº§ç‰¹å¾æå–å™¨
    é€‚åˆè¾¹ç¼˜éƒ¨ç½²
    """
    
    INPUT_SIZE = (128, 256)
    
    def _build_model(self) -> nn.Module:
        """æ„å»ºOSNetæ¨¡å‹"""
        try:
            # å°è¯•å¯¼å…¥torchreid
            import torchreid
            model = torchreid.models.build_model(
                name="osnet_x1_0",
                num_classes=1,
                pretrained=True,
                loss="softmax",
            )
            # ä¿®æ”¹æœ€åçš„åˆ†ç±»å±‚
            in_features = model.classifier.in_features
            model.classifier = nn.Linear(in_features, self.feature_dim)
            return model
        except ImportError:
            print("torchreidæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆOSNet")
            return self._build_lightweight_model()
    
    def _build_lightweight_model(self) -> nn.Module:
        """æ„å»ºè½»é‡çº§OSNet-likeæ¨¡å‹"""
        class OSNetLite(nn.Module):
            def __init__(self, feature_dim=128):
                super().__init__()
                self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1)
                self.bn1 = nn.BatchNorm2d(64)
                self.relu = nn.ReLU(inplace=True)
                
                # è½»é‡çº§ç“¶é¢ˆå±‚
                self.layer1 = self._make_layer(64, 128, 2)
                self.layer2 = self._make_layer(128, 256, 2)
                self.layer3 = self._make_layer(256, 512, 2)
                
                self.avgpool = nn.AdaptiveAvgPool2d(1)
                self.fc = nn.Linear(512, feature_dim)
            
            def _make_layer(self, in_ch, out_ch, stride):
                return nn.Sequential(
                    nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                    nn.Conv2d(out_ch, out_ch, 3, padding=1),
                    nn.BatchNorm2d(out_ch),
                    nn.ReLU(inplace=True),
                )
            
            def forward(self, x):
                x = self.relu(self.bn1(self.conv1(x)))
                x = self.layer1(x)
                x = self.layer2(x)
                x = self.layer3(x)
                x = self.avgpool(x)
                x = x.view(x.size(0), -1)
                x = self.fc(x)
                return F.normalize(x, p=2, dim=1)
        
        return OSNetLite(self.feature_dim)


class FallbackReIDExtractor(FastReIDExtractor):
    """
    æé€Ÿæ‹‰å–ã€ç»å¯¹ä¸ä¼šç½‘ç»œè¶…æ—¶çš„å¤‡ç”¨ ReID ç‰¹å¾æå–å™¨
    ä½¿ç”¨ PyTorch å®˜æ–¹ CDN çš„ ResNet50 é¢„è®­ç»ƒæƒé‡
    """
    
    INPUT_SIZE = (128, 256)  # (å®½, é«˜)
    MEAN = [0.485, 0.456, 0.406]
    STD = [0.229, 0.224, 0.225]
    
    def __init__(
        self,
        model_path: str = None,  # ä¸éœ€è¦è·¯å¾„
        device: str = "cuda:0",
        feature_dim: int = 2048,  # ResNet50 è¾“å‡ºç»´åº¦
        batch_size: int = 64,
        half_precision: bool = True,
    ):
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        self.feature_dim = feature_dim
        self.batch_size = batch_size
        self.half_precision = half_precision and self.device.type == "cuda"
        
        self._load_model()
        self._warmup()
    
    def _load_model(self):
        """åŠ è½½ PyTorch å®˜æ–¹ ResNet50"""
        print("ğŸš€ [ç½‘ç»œç•…é€šä¿éšœ] æ­£åœ¨ä» PyTorch å®˜æ–¹ CDN æ‹‰å– ResNet50 é¢„è®­ç»ƒæƒé‡...")
        
        try:
            # ä½¿ç”¨æœ€æ–°çš„ V2 æƒé‡ï¼Œèµ°å›½å†… CDN
            resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
        except Exception as e:
            print(f"  è­¦å‘Š: ä¸‹è½½æƒé‡å¤±è´¥ {e}ï¼Œä½¿ç”¨é»˜è®¤æƒé‡")
            resnet = models.resnet50(pretrained=True)
        
        # ç æ‰æœ€åçš„åˆ†ç±»å±‚ï¼Œåªä¿ç•™ç‰¹å¾æå–
        self.backbone = nn.Sequential(*list(resnet.children())[:-1])
        self.backbone = self.backbone.to(self.device)
        self.backbone.eval()
        
        # å†»ç»“æ‰€æœ‰å‚æ•°
        for param in self.backbone.parameters():
            param.requires_grad = False
        
        if self.half_precision:
            self.backbone = self.backbone.half()
        
        print("âœ… [æˆåŠŸ] å¤‡ç”¨ ReID (ResNet50-ImageNet) åŠ è½½å®Œæ¯•ï¼å½»åº•å‘Šåˆ«éšæœºåˆå§‹åŒ–ï¼")
    
    def _warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        dummy_input = torch.zeros(
            1, 3, self.INPUT_SIZE[1], self.INPUT_SIZE[0],
            device=self.device
        )
        if self.half_precision:
            dummy_input = dummy_input.half()
        
        with torch.no_grad():
            for _ in range(3):
                _ = self.backbone(dummy_input)
        
        print("ReIDæ¨¡å‹é¢„çƒ­å®Œæˆ")
    
    def preprocess(self, image: np.ndarray) -> torch.Tensor:
        """é¢„å¤„ç†"""
        img = cv2.resize(image, self.INPUT_SIZE)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = img.astype(np.float32) / 255.0
        
        mean = np.array(self.MEAN).reshape(1, 1, 3)
        std = np.array(self.STD).reshape(1, 1, 3)
        img = (img - mean) / std
        
        img = np.transpose(img, (2, 0, 1))
        tensor = torch.from_numpy(img).unsqueeze(0).to(self.device)
        
        if self.half_precision:
            tensor = tensor.half()
        
        return tensor
    
    @torch.no_grad()
    def extract(self, image: np.ndarray) -> np.ndarray:
        """æå–å•å¼ å›¾åƒç‰¹å¾"""
        tensor = self.preprocess(image)
        feature = self.backbone(tensor)
        feature = feature.view(feature.size(0), -1)
        feature = F.normalize(feature, p=2, dim=1)
        return feature.cpu().numpy().squeeze()
    
    @torch.no_grad()
    def extract_batch(self, images: List[np.ndarray]) -> np.ndarray:
        """æ‰¹é‡æå–ç‰¹å¾"""
        if not images:
            return np.zeros((0, self.feature_dim), dtype=np.float32)
        
        features = []
        
        for i in range(0, len(images), self.batch_size):
            batch_images = images[i:i + self.batch_size]
            
            batch_tensors = []
            for img in batch_images:
                tensor = self.preprocess(img)
                batch_tensors.append(tensor)
            
            batch_input = torch.cat(batch_tensors, dim=0)
            batch_features = self.backbone(batch_input)
            batch_features = batch_features.view(batch_features.size(0), -1)
            batch_features = F.normalize(batch_features, p=2, dim=1)
            
            features.append(batch_features.cpu().numpy())
        
        return np.concatenate(features, axis=0)


class OpenVINOReIDExtractor(FastReIDExtractor):
    """
    OpenVINO ReID ç‰¹å¾æå–å™¨
    ä½¿ç”¨ Intel OpenVINO ä¼˜åŒ–çš„è¡Œäººé‡è¯†åˆ«æ¨¡å‹
    """
    
    INPUT_SIZE = (128, 256)  # OpenVINO æ¨¡å‹è¾“å…¥å°ºå¯¸ (å®½, é«˜)
    
    def __init__(
        self,
        model_path: str,  # XML æ–‡ä»¶è·¯å¾„
        device: str = "cpu",  # OpenVINO å¯ä»¥ç”¨ CPU/GPU/MYRIAD
        feature_dim: int = 256,  # OpenVINO Retail æ¨¡å‹è¾“å‡º 256 ç»´
        batch_size: int = 32,
        half_precision: bool = False,
    ):
        self.device = device
        self.feature_dim = feature_dim
        self.batch_size = batch_size
        self.half_precision = half_precision
        
        self._load_model(model_path)
        self._warmup()
    
    def _load_model(self, model_path: str):
        """åŠ è½½ OpenVINO æ¨¡å‹"""
        try:
            import openvino as ov
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… OpenVINO: pip install openvino")
        
        print(f"ğŸš€ åŠ è½½ OpenVINO ReID æ¨¡å‹: {model_path}")
        
        # åˆ›å»º OpenVINO Core
        core = ov.Core()
        
        # è¯»å–æ¨¡å‹ (.xml å’Œ .bin)
        model = core.read_model(model_path)
        
        # ç¼–è¯‘æ¨¡å‹
        # è®¾å¤‡é€‰æ‹©: CPU (é»˜è®¤), GPU (å¦‚æœæœ‰ Intel GPU), AUTO (è‡ªåŠ¨é€‰æ‹©)
        compile_device = "GPU" if "GPU" in core.available_devices else "CPU"
        self.model = core.compile_model(model, compile_device)
        
        # è·å–è¾“å…¥è¾“å‡º
        self.input_layer = self.model.input(0)
        self.output_layer = self.model.output(0)
        
        print(f"âœ… OpenVINO æ¨¡å‹åŠ è½½æˆåŠŸï¼è®¾å¤‡: {compile_device}")
        print(f"   è¾“å…¥å½¢çŠ¶: {self.input_layer.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {self.output_layer.shape}")
    
    def _warmup(self):
        """æ¨¡å‹é¢„çƒ­"""
        dummy_input = np.zeros((1, 3, self.INPUT_SIZE[1], self.INPUT_SIZE[0]), dtype=np.float32)
        for _ in range(3):
            _ = self.model(dummy_input)
        print("ReIDæ¨¡å‹é¢„çƒ­å®Œæˆ")
    
    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç† - OpenVINO éœ€è¦ numpy æ•°ç»„"""
        img = cv2.resize(image, self.INPUT_SIZE)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # HWC -> CHW
        img = np.transpose(img, (2, 0, 1))
        
        # å½’ä¸€åŒ–åˆ° [0, 1]
        img = img.astype(np.float32) / 255.0
        
        # æ·»åŠ  batch ç»´åº¦: (1, 3, H, W)
        img = np.expand_dims(img, axis=0)
        
        return img
    
    def extract(self, image: np.ndarray) -> np.ndarray:
        """æå–å•å¼ å›¾åƒç‰¹å¾"""
        input_data = self.preprocess(image)
        feature = self.model(input_data)[self.output_layer]
        
        # L2 å½’ä¸€åŒ–
        feature = feature.squeeze()
        norm = np.linalg.norm(feature)
        if norm > 0:
            feature = feature / norm
        
        return feature
    
    def extract_batch(self, images: List[np.ndarray]) -> np.ndarray:
        """æ‰¹é‡æå–ç‰¹å¾ - OpenVINO æ¨¡å‹åªæ”¯æŒ batch=1ï¼Œé€ä¸ªæ¨ç†"""
        if not images:
            return np.zeros((0, self.feature_dim), dtype=np.float32)
        
        features = []
        
        for img in images:
            # é€ä¸ªæ¨ç†ï¼ˆOpenVINO Retail æ¨¡å‹å›ºå®š batch=1ï¼‰
            input_data = self.preprocess(img)
            feature = self.model(input_data)[self.output_layer]
            
            # L2 å½’ä¸€åŒ–
            feature = feature.squeeze()
            norm = np.linalg.norm(feature)
            if norm > 0:
                feature = feature / norm
            
            features.append(feature)
        
        return np.array(features, dtype=np.float32)


def create_reid_extractor(config: dict) -> FastReIDExtractor:
    """
    ä»é…ç½®åˆ›å»ºReIDæå–å™¨
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        ReIDæå–å™¨å®ä¾‹
    """
    model_type = config.get("model_type", "fastreid")
    model_path = config.get("model_path", "")
    
    # æ£€æµ‹æ˜¯å¦ä¸º OpenVINO æ¨¡å‹ (.xml)
    if model_path.endswith(".xml"):
        print("ä½¿ç”¨ OpenVINO ReID æ¨¡å‹")
        return OpenVINOReIDExtractor(
            model_path=model_path,
            device=config.get("device", "cpu"),
            feature_dim=config.get("feature_dim", 256),
            batch_size=config.get("batch_size", 32),
            half_precision=False,  # OpenVINO ä¸éœ€è¦ FP16
        )
    
    # å¦‚æœæŒ‡å®šäº† resnet50 æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ Fallback
    if model_type.lower() == "resnet50":
        print("ä½¿ç”¨ PyTorch å®˜æ–¹ ResNet50 ä½œä¸º ReID ç‰¹å¾æå–å™¨")
        return FallbackReIDExtractor(
            device=config.get("device", "cuda:0"),
            feature_dim=2048,
            batch_size=config.get("batch_size", 64),
            half_precision=config.get("half_precision", True),
        )
    elif model_type.lower() == "osnet":
        cls = OSNetExtractor
    else:
        cls = FastReIDExtractor
    
    return cls(
        model_path=config.get("model_path", "weights/fastreid_mot20.pth"),
        device=config.get("device", "cuda:0"),
        feature_dim=config.get("feature_dim", 128),
        batch_size=config.get("batch_size", 32),
        half_precision=config.get("half_precision", True),
    )
